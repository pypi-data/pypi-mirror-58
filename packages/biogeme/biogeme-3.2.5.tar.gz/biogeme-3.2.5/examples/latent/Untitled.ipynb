{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
       "               method='minres', n_factors=3, rotation='varimax',\n",
       "               rotation_kwargs={}, use_smc=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# The following package can be installed using\n",
    "# pip install factor_analyzer\n",
    "# See https://github.com/EducationalTestingService/factor_analyzer\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "# We first extract the columns containing the indicators\n",
    "indicators = pd.read_csv(\"optima.dat\",sep='\\t',usecols=[\"Envir01\",\n",
    "        \"Envir02\",\n",
    "\t\"Envir03\",\n",
    "\t\"Envir04\",\n",
    "\t\"Envir05\",\n",
    "\t\"Envir06\",\n",
    "\t\"Mobil01\",\n",
    "\t\"Mobil02\",\n",
    "\t\"Mobil03\",\n",
    "\t\"Mobil04\",\n",
    "\t\"Mobil05\",\n",
    "\t\"Mobil06\",\n",
    "\t\"Mobil07\",\n",
    "\t\"Mobil08\",\n",
    "\t\"Mobil09\",\n",
    "\t\"Mobil10\",\n",
    "\t\"Mobil11\",\n",
    "\t\"Mobil12\",\n",
    "\t\"Mobil13\",\n",
    "\t\"Mobil14\",\n",
    "\t\"Mobil15\",\n",
    "\t\"Mobil16\",\n",
    "\t\"Mobil17\",\n",
    "\t\"Mobil18\",\n",
    "\t\"Mobil19\",\n",
    "\t\"Mobil20\",\n",
    "\t\"Mobil21\",\n",
    "\t\"Mobil22\",\n",
    "\t\"Mobil23\",\n",
    "\t\"Mobil24\",\n",
    "\t\"Mobil25\",\n",
    "\t\"Mobil26\",\n",
    "\t\"Mobil27\",\n",
    "\t\"ResidCh01\",\n",
    "\t\"ResidCh02\",\n",
    "\t\"ResidCh03\",\n",
    "\t\"ResidCh04\",\n",
    "\t\"ResidCh05\",\n",
    "\t\"ResidCh06\",\n",
    "\t\"ResidCh07\",\n",
    "\t\"LifSty01\",\n",
    "\t\"LifSty02\",\n",
    "\t\"LifSty03\",\n",
    "\t\"LifSty04\",\n",
    "\t\"LifSty05\",\n",
    "\t\"LifSty06\",\n",
    "\t\"LifSty07\",\n",
    "\t\"LifSty08\",\n",
    "\t\"LifSty09\",\n",
    "\t\"LifSty10\",\n",
    "\t\"LifSty11\",\n",
    "\t\"LifSty12\",\n",
    "\t\"LifSty13\",\n",
    "\t\"LifSty14\"])\n",
    "\n",
    "# Negative values are missing values. \n",
    "indicators[indicators <= 0] = np.nan\n",
    "indicators = indicators.dropna(axis = 0, how = 'any') \n",
    "\n",
    "# We perform the factor analysis\n",
    "fa = FactorAnalyzer(rotation='varimax')\n",
    "#fa.analyze(indicators,3,rotation='varimax')\n",
    "fa.fit(indicators)\n",
    "fa.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on FactorAnalyzer in module factor_analyzer.factor_analyzer object:\n",
      "\n",
      "class FactorAnalyzer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  FactorAnalyzer(n_factors=3, rotation='promax', method='minres', use_smc=True, is_corr_matrix=False, bounds=(0.005, 1), impute='median', rotation_kwargs=None)\n",
      " |  \n",
      " |  A FactorAnalyzer class, which -\n",
      " |      (1) Fits a factor analysis model using minres, maximum likelihood,\n",
      " |          or principal factor extraction and returns the loading matrix\n",
      " |      (2) Optionally performs a rotation, with method including:\n",
      " |  \n",
      " |          (a) varimax (orthogonal rotation)\n",
      " |          (b) promax (oblique rotation)\n",
      " |          (c) oblimin (oblique rotation)\n",
      " |          (d) oblimax (orthogonal rotation)\n",
      " |          (e) quartimin (oblique rotation)\n",
      " |          (f) quartimax (orthogonal rotation)\n",
      " |          (g) equamax (orthogonal rotation)\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_factors : int, optional\n",
      " |      The number of factors to select.\n",
      " |      Defaults to 3.\n",
      " |  rotation : str, optional\n",
      " |      The type of rotation to perform after\n",
      " |      fitting the factor analysis model.\n",
      " |      If set to None, no rotation will be performed,\n",
      " |      nor will any associated Kaiser normalization.\n",
      " |  \n",
      " |      Methods include:\n",
      " |  \n",
      " |          (a) varimax (orthogonal rotation)\n",
      " |          (b) promax (oblique rotation)\n",
      " |          (c) oblimin (oblique rotation)\n",
      " |          (d) oblimax (orthogonal rotation)\n",
      " |          (e) quartimin (oblique rotation)\n",
      " |          (f) quartimax (orthogonal rotation)\n",
      " |          (g) equamax (orthogonal rotation)\n",
      " |  \n",
      " |      Defaults to 'promax'.\n",
      " |  \n",
      " |  method : {'minres', 'ml', 'principal'}, optional\n",
      " |      The fitting method to use, either MINRES or\n",
      " |      Maximum Likelihood.\n",
      " |      Defaults to 'minres'.\n",
      " |  use_smc : bool, optional\n",
      " |      Whether to use squared multiple correlation\n",
      " |      as starting guesses for factor analysis.\n",
      " |      Defaults to True.\n",
      " |  bounds : tuple, optional\n",
      " |      The lower and upper bounds on the variables\n",
      " |      for \"L-BFGS-B\" optimization.\n",
      " |      Defaults to (0.005, 1).\n",
      " |  impute : {'drop', 'mean', 'median'}, optional\n",
      " |      If missing values are present in the data, either use\n",
      " |      list-wise deletion ('drop') or impute the column median\n",
      " |      ('median') or column mean ('mean').\n",
      " |  use_corr_matrix : bool, optional\n",
      " |      Set to true if the `data` is the correlation\n",
      " |      matrix.\n",
      " |      Defaults to False.\n",
      " |  rotation_kwargs, optional\n",
      " |      Additional key word arguments\n",
      " |      are passed to the rotation method.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  loadings : numpy array\n",
      " |      The factor loadings matrix.\n",
      " |      Default to None, if `analyze()` has not\n",
      " |      been called.\n",
      " |  corr : numpy array\n",
      " |      The original correlation matrix.\n",
      " |      Default to None, if `analyze()` has not\n",
      " |      been called.\n",
      " |  rotation_matrix : numpy array\n",
      " |      The rotation matrix, if a rotation\n",
      " |      has been performed.\n",
      " |  structure :numpy array or None\n",
      " |      The structure loading matrix.\n",
      " |      This only exists if the rotation\n",
      " |      is promax.\n",
      " |  psi : numpy array or None\n",
      " |      The factor correlations\n",
      " |      matrix. This only exists\n",
      " |      if the rotation is oblique.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  This code was partly derived from the excellent R package\n",
      " |  `psych`.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  [1] https://github.com/cran/psych/blob/master/R/fa.R\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import pandas as pd\n",
      " |  >>> from factor_analyzer import FactorAnalyzer\n",
      " |  >>> df_features = pd.read_csv('tests/data/test02.csv')\n",
      " |  >>> fa = FactorAnalyzer(rotation=None)\n",
      " |  >>> fa.fit(df_features)\n",
      " |  FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
      " |          method='minres', n_factors=3, rotation=None, rotation_kwargs={},\n",
      " |          use_smc=True)\n",
      " |  >>> fa.loadings_\n",
      " |  array([[-0.12991218,  0.16398154,  0.73823498],\n",
      " |         [ 0.03899558,  0.04658425,  0.01150343],\n",
      " |         [ 0.34874135,  0.61452341, -0.07255667],\n",
      " |         [ 0.45318006,  0.71926681, -0.07546472],\n",
      " |         [ 0.36688794,  0.44377343, -0.01737067],\n",
      " |         [ 0.74141382, -0.15008235,  0.29977512],\n",
      " |         [ 0.741675  , -0.16123009, -0.20744495],\n",
      " |         [ 0.82910167, -0.20519428,  0.04930817],\n",
      " |         [ 0.76041819, -0.23768727, -0.1206858 ],\n",
      " |         [ 0.81533404, -0.12494695,  0.17639683]])\n",
      " |  >>> fa.get_communalities()\n",
      " |  array([0.588758  , 0.00382308, 0.50452402, 0.72841183, 0.33184336,\n",
      " |         0.66208428, 0.61911036, 0.73194557, 0.64929612, 0.71149718])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      FactorAnalyzer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_factors=3, rotation='promax', method='minres', use_smc=True, is_corr_matrix=False, bounds=(0.005, 1), impute='median', rotation_kwargs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Fit the factor analysis model using either\n",
      " |      minres, ml, or principal solutions. By default, use SMC\n",
      " |      as starting guesses.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like\n",
      " |          The data to analyze.\n",
      " |      y : ignored\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> from factor_analyzer import FactorAnalyzer\n",
      " |      >>> df_features = pd.read_csv('tests/data/test02.csv')\n",
      " |      >>> fa = FactorAnalyzer(rotation=None)\n",
      " |      >>> fa.fit(df_features)\n",
      " |      FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
      " |              method='minres', n_factors=3, rotation=None, rotation_kwargs={},\n",
      " |              use_smc=True)\n",
      " |      >>> fa.loadings_\n",
      " |      array([[-0.12991218,  0.16398154,  0.73823498],\n",
      " |             [ 0.03899558,  0.04658425,  0.01150343],\n",
      " |             [ 0.34874135,  0.61452341, -0.07255667],\n",
      " |             [ 0.45318006,  0.71926681, -0.07546472],\n",
      " |             [ 0.36688794,  0.44377343, -0.01737067],\n",
      " |             [ 0.74141382, -0.15008235,  0.29977512],\n",
      " |             [ 0.741675  , -0.16123009, -0.20744495],\n",
      " |             [ 0.82910167, -0.20519428,  0.04930817],\n",
      " |             [ 0.76041819, -0.23768727, -0.1206858 ],\n",
      " |             [ 0.81533404, -0.12494695,  0.17639683]])\n",
      " |  \n",
      " |  get_communalities(self)\n",
      " |      Calculate the communalities, given the\n",
      " |      factor loading matrix.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      communalities : numpy array\n",
      " |          The communalities from the factor loading\n",
      " |          matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> from factor_analyzer import FactorAnalyzer\n",
      " |      >>> df_features = pd.read_csv('tests/data/test02.csv')\n",
      " |      >>> fa = FactorAnalyzer(rotation=None)\n",
      " |      >>> fa.fit(df_features)\n",
      " |      FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
      " |              method='minres', n_factors=3, rotation=None, rotation_kwargs={},\n",
      " |              use_smc=True)\n",
      " |      >>> fa.get_communalities()\n",
      " |      array([0.588758  , 0.00382308, 0.50452402, 0.72841183, 0.33184336,\n",
      " |             0.66208428, 0.61911036, 0.73194557, 0.64929612, 0.71149718])\n",
      " |  \n",
      " |  get_eigenvalues(self)\n",
      " |      Calculate the eigenvalues, given the\n",
      " |      factor correlation matrix.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      original_eigen_values : numpy array\n",
      " |          The original eigen values\n",
      " |      common_factor_eigen_values : numpy array\n",
      " |          The common factor eigen values\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> from factor_analyzer import FactorAnalyzer\n",
      " |      >>> df_features = pd.read_csv('tests/data/test02.csv')\n",
      " |      >>> fa = FactorAnalyzer(rotation=None)\n",
      " |      >>> fa.fit(df_features)\n",
      " |      FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
      " |              method='minres', n_factors=3, rotation=None, rotation_kwargs={},\n",
      " |              use_smc=True)\n",
      " |      >>> fa.get_eigenvalues()\n",
      " |      (array([ 3.51018854,  1.28371018,  0.73739507,  0.1334704 ,  0.03445558,\n",
      " |              0.0102918 , -0.00740013, -0.03694786, -0.05959139, -0.07428112]),\n",
      " |       array([ 3.51018905,  1.2837105 ,  0.73739508,  0.13347082,  0.03445601,\n",
      " |              0.01029184, -0.0074    , -0.03694834, -0.05959057, -0.07428059]))\n",
      " |  \n",
      " |  get_factor_variance(self)\n",
      " |      Calculate the factor variance information,\n",
      " |      including variance, proportional variance\n",
      " |      and cumulative variance for each factor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      variance : numpy array\n",
      " |          The factor variances.\n",
      " |      proportional_variance : numpy array\n",
      " |          The proportional factor variances.\n",
      " |      cumulative_variances : numpy array\n",
      " |          The cumulative factor variances.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> from factor_analyzer import FactorAnalyzer\n",
      " |      >>> df_features = pd.read_csv('tests/data/test02.csv')\n",
      " |      >>> fa = FactorAnalyzer(rotation=None)\n",
      " |      >>> fa.fit(df_features)\n",
      " |      FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
      " |              method='minres', n_factors=3, rotation=None, rotation_kwargs={},\n",
      " |              use_smc=True)\n",
      " |      >>> # 1. Sum of squared loadings (variance)\n",
      " |      ... # 2. Proportional variance\n",
      " |      ... # 3. Cumulative variance\n",
      " |      >>> fa.get_factor_variance()\n",
      " |      (array([3.51018854, 1.28371018, 0.73739507]),\n",
      " |       array([0.35101885, 0.12837102, 0.07373951]),\n",
      " |       array([0.35101885, 0.47938987, 0.55312938]))\n",
      " |  \n",
      " |  get_uniquenesses(self)\n",
      " |      Calculate the uniquenesses, given the\n",
      " |      factor loading matrix.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      uniquenesses : numpy array\n",
      " |          The uniquenesses from the factor loading\n",
      " |          matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> from factor_analyzer import FactorAnalyzer\n",
      " |      >>> df_features = pd.read_csv('tests/data/test02.csv')\n",
      " |      >>> fa = FactorAnalyzer(rotation=None)\n",
      " |      >>> fa.fit(df_features)\n",
      " |      FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
      " |              method='minres', n_factors=3, rotation=None, rotation_kwargs={},\n",
      " |              use_smc=True)\n",
      " |      >>> fa.get_uniquenesses()\n",
      " |      array([0.411242  , 0.99617692, 0.49547598, 0.27158817, 0.66815664,\n",
      " |             0.33791572, 0.38088964, 0.26805443, 0.35070388, 0.28850282])\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Get the factor scores for new data set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          The data to score using the fitted factor model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array, shape (n_samples, n_components)\n",
      " |          The latent variables of X.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> import pandas as pd\n",
      " |      >>> from factor_analyzer import FactorAnalyzer\n",
      " |      >>> df_features = pd.read_csv('tests/data/test02.csv')\n",
      " |      >>> fa = FactorAnalyzer(rotation=None)\n",
      " |      >>> fa.fit(df_features)\n",
      " |      FactorAnalyzer(bounds=(0.005, 1), impute='median', is_corr_matrix=False,\n",
      " |              method='minres', n_factors=3, rotation=None, rotation_kwargs={},\n",
      " |              use_smc=True)\n",
      " |      >>> fa.transform(df_features)\n",
      " |      array([[-1.05141425,  0.57687826,  0.1658788 ],\n",
      " |             [-1.59940101,  0.89632125,  0.03824552],\n",
      " |             [-1.21768164, -1.16319406,  0.57135189],\n",
      " |             ...,\n",
      " |             [ 0.13601554,  0.03601086,  0.28813877],\n",
      " |             [ 1.86904519, -0.3532394 , -0.68170573],\n",
      " |             [ 0.86133386,  0.18280695, -0.79170903]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : numpy array of shape [n_samples, n_features]\n",
      " |          Training set.\n",
      " |      \n",
      " |      y : numpy array of shape [n_samples]\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : numpy array of shape [n_samples, n_features_new]\n",
      " |          Transformed array.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
