{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Mixed-style workflow implementation using named output (data-flow driven)\n",
    "\n",
    "Instead of using wild-card pattern as shown in `Mixed_Style.ipynb`, here we use a less powerful yet more intuitive approach, via `named_output`, to define simple dependencies for mixed-style workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: beta = [3, 1.5, 0, 0, 2, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Simulate sparse data-sets\n",
    "[simulation]\n",
    "depends: R_library(\"MASS>=7.3\")\n",
    "parameter: N = (40, 200) # training and testing samples\n",
    "parameter: rstd = 3\n",
    "id = [x for x in range(1,6)]\n",
    "input: for_each = 'id'\n",
    "output: train = f\"data_{_id}.train.csv\", test = f\"data_{_id}.test.csv\"\n",
    "R: expand = \"${ }\"\n",
    "  set.seed(${_id})\n",
    "  N = sum(c(${paths(N):,}))\n",
    "  p = length(c(${paths(beta):,}))\n",
    "  X = MASS::mvrnorm(n = N, rep(0, p), 0.5^abs(outer(1:p, 1:p, FUN = \"-\")))\n",
    "  Y = X %*% c(${paths(beta):,}) + rnorm(N, mean = 0, sd = ${rstd})\n",
    "  Xtrain = X[1:${N[0]},]; Xtest = X[(${N[0]}+1):(${N[0]}+${N[1]}),]\n",
    "  Ytrain = Y[1:${N[0]}]; Ytest = Y[(${N[0]}+1):(${N[0]}+${N[1]})]\n",
    "  write.table(cbind(Ytrain, Xtrain), ${_output[0]:r}, row.names = F, col.names = F, sep = ',')\n",
    "  write.table(cbind(Ytest, Xtest), ${_output[1]:r}, row.names = F, col.names = F, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Ridge regression model implemented in R\n",
    "# Build predictor via cross-validation and make prediction\n",
    "[ridge_1 (model fitting)]\n",
    "depends: R_library(\"glmnet>=2.0\")\n",
    "parameter: nfolds = 5\n",
    "input: named_output('train'), named_output('test')\n",
    "output: pred = f\"{_input[0]:nn}.ridge.predicted.csv\", coef = f\"{_input[0]:nn}.ridge.coef.csv\"\n",
    "R: expand = \"${ }\"\n",
    "  train = read.csv(${_input[0]:r}, header = F)\n",
    "  test = read.csv(${_input[1]:r}, header = F)\n",
    "  model = glmnet::cv.glmnet(as.matrix(train[,-1]), train[,1], family = \"gaussian\", alpha = 0, nfolds = ${nfolds}, intercept = F)\n",
    "  betahat = as.vector(coef(model, s = \"lambda.min\")[-1])\n",
    "  Ypred = predict(model, as.matrix(test[,-1]), s = \"lambda.min\")\n",
    "  write.table(Ypred, ${_output[0]:r}, row.names = F, col.names = F, sep = ',')\n",
    "  write.table(betahat, ${_output[1]:r}, row.names = F, col.names = F, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# LASSO model implemented in Python\n",
    "# Build predictor via cross-validation and make prediction\n",
    "[lasso_1 (model fitting)]\n",
    "depends: Py_Module(\"sklearn>=0.18.1\"), Py_Module(\"numpy>=1.6.1\"), Py_Module(\"scipy>=0.9\") \n",
    "parameter: nfolds = 5\n",
    "input: named_output('train'), named_output('test')\n",
    "output: pred = f\"{_input[0]:nn}.lasso.predicted.csv\", coef = f\"{_input[0]:nn}.lasso.coef.csv\"\n",
    "python: expand = \"${ }\"\n",
    "  import numpy as np\n",
    "  from sklearn.linear_model import LassoCV\n",
    "  train = np.genfromtxt(${_input[0]:r}, delimiter = \",\")\n",
    "  test = np.genfromtxt(${_input[1]:r}, delimiter = \",\")\n",
    "  model = LassoCV(cv = ${nfolds}, fit_intercept = False).fit(train[:,1:], train[:,1])\n",
    "  Ypred = model.predict(test[:,1:])\n",
    "  np.savetxt(${_output[0]:r}, Ypred)\n",
    "  np.savetxt(${_output[1]:r}, model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Evaluate predictors by calculating mean squared error\n",
    "# of prediction vs truth (first line of output)\n",
    "# and of betahat vs truth (2nd line of output)\n",
    "[ridge_2, lasso_2 (evaluate)]\n",
    "input: y = named_output('test'), yhat = output_from(-1)['pred'], coef = output_from(-1)['coef']\n",
    "output: f\"{_input[0]:nn}.mse.csv\"\n",
    "R: expand = \"${ }\", stderr = False\n",
    "  b = c(${paths(beta):,})\n",
    "  Ytruth = as.matrix(read.csv(${path(_input[0]):r}, header = F)[,-1]) %*% b\n",
    "  Ypred = scan(${_input[1]:r})\n",
    "  prediction_mse = mean((Ytruth - Ypred)^2)\n",
    "  betahat = scan(${_input[2]:r})\n",
    "  estimation_mse = mean((betahat - b) ^ 2)\n",
    "  cat(paste(prediction_mse, estimation_mse), file = ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[default]\n",
    "sos_run(['ridge', 'lasso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "%sosrun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
